# Story Builder App - Phase 1 MVP

A desktop application for creating serialized episodic stories through human-AI collaboration.

## âœ… Features (Phase 1)

**Project Management**
- Create and manage multiple story projects
- Auto-save functionality
- Project metadata (title, genre, description)

**World Building**
- Collaborative world development with AI
- World overview editor
- Locations management
- Character templates
- Factions, religions, NPCs, glossary
- Structured JSON storage

**AI Integration**
- Local Ollama integration
- Real-time AI status monitoring
- Available models listing
- Adjustable creativity (temperature)
- Chat interface for collaboration

**Consistency Validation**
- Check world building completeness
- Validate location IDs and routes
- Verify character relationships
- Detect duplicate IDs
- Provide suggestions for improvements

**Modern UI**
- Three-panel layout (Navigation | Editor | AI Chat)
- Dark theme optimized for long writing sessions
- Responsive components
- Save status indicators
## ğŸ›  Tech Stack

**Backend:**
- Python 3.10+
- Flask (REST API)
- Ollama (Local AI)

**Frontend:**
- React 18
- Vite (Build tool)
- Axios (API calls)

**Storage:**
- JSON files (local filesystem)

## ğŸ“‹ Prerequisites

1. **Python 3.10 or higher**
   ```bash
   python --version
   ```

2. **Node.js 18 or higher**
   ```bash
   node --version
   ```

3. **Ollama** (for AI features)
   - Download from: https://ollama.ai
   - Install and run:
     ```bash
     ollama serve
     ```
   - Pull a model:
     ```bash
     ollama pull llama3.2
     ```

## ğŸš€ Installation

### 1. Clone Repository

```bash
git clone https://github.com/madbowman/story-generator.git
cd story-generator
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install
```

## ğŸƒ Running the Application

You need **3 terminals**:

### Terminal 1 - Backend Server

```bash
cd backend
# Activate venv if not already activated
python app.py
```

âœ“ Backend will start on: `http://localhost:5000`

### Terminal 2 - Frontend Dev Server

```bash
cd frontend
npm run dev
```

âœ“ Frontend will start on: `http://localhost:3000`

### Terminal 3 - Ollama

```bash
ollama serve
```

### Windows Users with Docker Desktop

If you get "This site can't be reached" on `http://localhost:3000`, ensure `vite.config.js` has:
```javascript
server: {
  host: '0.0.0.0',
  port: 3000,
  // ...
}

## ğŸ“– Usage

1. **Open your browser** to `http://localhost:3000`

2. **Check AI Status** in the top-right corner:
   - Green "â— Running" means Ollama is connected
   - Red "â— Offline" means Ollama is not available

3. **Create a New Project:**
   - Click the "+" button next to the project selector
   - Fill in title, genre, and description
   - Click "Create Project"

4. **Build Your World:**
   - Navigate to "World Builder" in the left sidebar
   - Fill in world overview details
   - Add locations, characters, factions, etc.
   - Use the AI Chat on the right to collaborate

5. **Collaborate with AI:**
   - Type messages in the AI Chat panel
   - AI will help you develop ideas
   - Adjust creativity with the temperature slider
   - Select different models from the dropdown

6. **Validate Consistency:**
   - Click "Check Consistency" button
   - Review warnings and suggestions
   - Fix any issues found

## ğŸ“ Project Structure

```
story-generator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                          # Flask application
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ai_integration/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ ollama_client.py        # Ollama API client
â”‚       â”œâ”€â”€ world_builder/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ project_manager.py      # Project CRUD
â”‚       â”‚   â””â”€â”€ world_builder.py        # World data management
â”‚       â””â”€â”€ consistency/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ validator.py            # Consistency checking
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json                    # Node dependencies
â”‚   â”œâ”€â”€ vite.config.js                  # Vite configuration
â”‚   â”œâ”€â”€ index.html                      # HTML entry point
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.jsx                    # React entry point
â”‚       â”œâ”€â”€ App.jsx                     # Main application
â”‚       â”œâ”€â”€ index.css                   # Global styles
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ api.js                  # Backend API calls
â”‚       â”œâ”€â”€ context/
â”‚       â”‚   â””â”€â”€ ProjectContext.jsx      # Project state management
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ AIStatus.jsx            # AI status indicator
â”‚           â”œâ”€â”€ ProjectSelector.jsx     # Project switcher
â”‚           â””â”€â”€ WorldBuilder/
â”‚               â””â”€â”€ WorldBuilder.jsx    # World building UI
â”‚
â””â”€â”€ projects/                           # User projects (auto-created)
    â””â”€â”€ [project_id]/
        â”œâ”€â”€ project_metadata.json
        â”œâ”€â”€ world/
        â”‚   â”œâ”€â”€ world_overview.json
        â”‚   â”œâ”€â”€ locations.json
        â”‚   â”œâ”€â”€ characters.json
        â”‚   â”œâ”€â”€ npcs.json
        â”‚   â”œâ”€â”€ factions.json
        â”‚   â”œâ”€â”€ religions.json
        â”‚   â”œâ”€â”€ glossary.json
        â”‚   â””â”€â”€ content.json
        â”œâ”€â”€ story/
        â”‚   â””â”€â”€ seasons/
        â”œâ”€â”€ state/
        â”‚   â”œâ”€â”€ current_state.json
        â”‚   â””â”€â”€ timeline.json
        â””â”€â”€ exports/
            â””â”€â”€ tts_scripts/
```

## ğŸ”Œ API Endpoints

### AI Endpoints
- `GET /api/ai/status` - Check Ollama status
- `GET /api/ai/models` - List available models
- `POST /api/ai/generate` - Generate AI response
- `POST /api/ai/chat` - Chat with conversation history

### Project Endpoints
- `GET /api/projects` - List all projects
- `POST /api/projects` - Create new project
- `GET /api/projects/<id>` - Load project data
- `DELETE /api/projects/<id>` - Delete project

### World Building Endpoints
- `GET /api/projects/<id>/world/<section>` - Get world section
- `PUT /api/projects/<id>/world/<section>` - Update world section

### Consistency Endpoints
- `POST /api/projects/<id>/consistency/check` - Validate consistency

### Health Check
- `GET /api/health` - Backend health check

## ğŸ› Troubleshooting

### Ollama Not Connecting

**Problem:** Red "â— Offline" in AI Status

**Solutions:**
1. Make sure Ollama is running: `ollama serve`
2. Check if models are installed: `ollama list`
3. Pull a model if needed: `ollama pull llama3.2`

### Backend Won't Start

**Problem:** Python errors when running `app.py`

**Solutions:**
1. Verify Python version: `python --version` (needs 3.10+)
2. Activate virtual environment
3. Check if all `__init__.py` files exist in modules
4. Reinstall dependencies: `pip install -r requirements.txt`

### Frontend Won't Start

**Problem:** npm errors when running `npm run dev`

**Solutions:**
1. Verify Node version: `node --version` (needs 18+)
2. Delete `node_modules` and reinstall:
   ```bash
   rm -rf node_modules
   npm install
   ```

### CORS Errors

**Problem:** Browser console shows CORS errors

**Solution:** Make sure both backend (5000) and frontend (3000) are running

### Projects Not Saving

**Problem:** Changes aren't persisted

**Solutions:**
1. Check `projects/` directory exists
2. Check file permissions
3. Look for errors in backend terminal
4. Verify save status indicator in header

### Import Errors

**Problem:** `ModuleNotFoundError` when running backend

**Solutions:**
1. Make sure you're in the `backend/` directory
2. Virtual environment is activated
3. All `__init__.py` files exist in:
   - `modules/`
   - `modules/ai_integration/`
   - `modules/world_builder/`
   - `modules/consistency/`

## ğŸ’¾ Data Storage

### Auto-Save
- Projects auto-save 30 seconds after changes
- Manual save triggered by editing fields
- Save status shown in header:
  - âœ“ Saved (green)
  - â³ Saving... (yellow)
  - âš  Error (red)

### JSON Files
- All project data stored in `projects/` directory
- Each project has its own folder with unique ID
- World, story, and state data in separate JSON files
- Human-readable format - easy to backup or edit manually
- No database required

### File Structure
Each project contains:
- **project_metadata.json** - Title, genre, timestamps
- **world/** - All world building data (8 files)
- **story/** - Episodes and seasons (Phase 2)
- **state/** - Current timeline and character positions
- **exports/** - TTS scripts (Phase 2)

## ğŸ¤– Using Different AI Models

1. List available models:
   ```bash
   ollama list
   ```

2. Pull a new model:
   ```bash
   ollama pull mistral
   ollama pull codellama
   ollama pull llama2
   ```

3. Model will appear in AI Chat dropdown
4. Select it to use for generation
5. Experiment with different models for different tasks

## ğŸ—º Roadmap

### Phase 2 - Episode Production (Next)
- ğŸ”² Episode editor with draft/refinement workflow
- ğŸ”² Season and arc management
- ğŸ”² Context window management (3-episode + summaries)
- ğŸ”² Advanced consistency engine (travel time, character tracking)
- ğŸ”² TTS script export for audio production
- ğŸ”² Timeline visualization

### Phase 3 - Polish & Features
- ğŸ”² Batch operations
- ğŸ”² Project templates
- ğŸ”² Import/export capabilities
- ğŸ”² Version history
- ğŸ”² Advanced search and filtering

## ğŸ“š Additional Documentation

- **QUICKSTART.md** - 5-minute getting started guide
- **DEVELOPMENT_CHECKLIST.md** - Development progress tracker
- **setup.sh** - Automated setup script (Mac/Linux)

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section above
2. Review backend terminal for error messages
3. Check browser console (F12) for frontend errors
4. Verify all prerequisites are installed
5. Make sure Ollama is running and has models

## ğŸ¤ Contributing

Phase 1 is complete! If you'd like to contribute to Phase 2:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

[Your License Here]

---

**Version:** 1.0 (Phase 1 MVP Complete âœ…)  
**Last Updated:** October 2025  
**Status:** Production Ready
